{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import sentencepiece as spm\n",
    "from transformers import ReformerConfig, ReformerModelWithLMHead, ReformerTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "NUM_BATCHES = None\n",
    "BATCH_SIZE = 6\n",
    "GRADIENT_ACCUMULATE_EVERY = 3\n",
    "LEARNING_RATE = 0.01\n",
    "VALIDATE_EVERY  = 20\n",
    "SEQ_LEN = 4608"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Encoding\n",
    "def encode(list_of_strings, pad_to_max_length=True, pad_token_id=0):\n",
    "    max_length = max([len(string) for string in list_of_strings])\n",
    "\n",
    "    # create emtpy tensors\n",
    "    attention_masks = torch.zeros((len(list_of_strings), max_length), dtype=torch.long)\n",
    "    input_ids = torch.full((len(list_of_strings), max_length), pad_token_id, dtype=torch.long)\n",
    "\n",
    "    for idx, string in enumerate(list_of_strings):\n",
    "        # make sure string is in byte format\n",
    "        if not isinstance(string, bytes):\n",
    "            string = str.encode(string)\n",
    "\n",
    "        input_ids[idx, :len(string)] = torch.tensor([x + 2 for x in string])\n",
    "        attention_masks[idx, :len(string)] = 1\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Decoding\n",
    "def decode(outputs_ids):\n",
    "    decoded_outputs = []\n",
    "    for output_ids in outputs_ids.tolist():\n",
    "        # transform id back to char IDs < 2 are simply transformed to \"\"\n",
    "        decoded_outputs.append(\"\".join([chr(x - 2) if x > 1 else \"\" for x in output_ids]))\n",
    "    return decoded_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[67, 68, 69, 70, 71, 72]]), tensor([[1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(['ABCDEF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\"--input=./data/tokenizer_training/AAresiduals.txt \\\n",
    "                                --vocab_size=28 \\\n",
    "                                --model_prefix=sequence_tokenizer \\\n",
    "                                --model_type=char \\\n",
    "                                --character_coverage=1.0\")\n",
    "tokenizer = ReformerTokenizer(vocab_file=\"sequence_tokenizer.model\", do_lower_case=False, model_max_length=SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = ReformerConfig.from_pretrained(\"google/reformer-enwik8\")\n",
    "configuration.axial_pos_shape = (64, 72)\n",
    "configuration.max_position_embeddings=SEQ_LEN\n",
    "configuration.vocab_size=tokenizer.vocab_size\n",
    "configuration.save_pretrained('model/config_enwik8_modified/')\n",
    "configuration = ReformerConfig.from_pretrained('model/config_enwik8_modified/')\n",
    "model = ReformerModelWithLMHead(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReformerModelWithLMHead(\n",
       "  (reformer): ReformerModel(\n",
       "    (embeddings): ReformerEmbeddings(\n",
       "      (word_embeddings): Embedding(28, 1024)\n",
       "      (position_embeddings): AxialPositionEmbeddings(\n",
       "        (weights): ParameterList(\n",
       "            (0): Parameter containing: [torch.FloatTensor of size 64x1x256]\n",
       "            (1): Parameter containing: [torch.FloatTensor of size 1x72x768]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder): ReformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LSHSelfAttention(\n",
       "              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LSHSelfAttention(\n",
       "              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LSHSelfAttention(\n",
       "              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ReformerLayer(\n",
       "          (attention): ReformerAttention(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (self_attention): LocalSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ReformerSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (feed_forward): ChunkReformerFeedForward(\n",
       "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dense): ReformerFeedForwardDense(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            )\n",
       "            (output): ReformerFeedForwardOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): ReformerOnlyLMHead(\n",
       "    (decoder): Linear(in_features=2048, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = torch.tensor(tokenizer.encode(\"ABCDEFGH\", add_special_tokens=True, pad_to_max_length=True)).unsqueeze(0)  # Batch size 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4608])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_id, labels = input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4608, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id[torch.argmax(prediction_scores, dim=2) == input_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 4,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 6, 1, 6, 2, 6, 2, 5]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.randint(7, (1,)).item() for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineByLineTextDataset(Dataset):\n",
    "    \"\"\"modified: \n",
    "    https://github.com/huggingface/transformers/blob/cb3c2212c79d7ff0a4a4e84c3db48371ecc1c15d/src/transformers/data/datasets/language_modeling.py#L77\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer, file_path: str):\n",
    "        assert os.path.isfile(file_path)\n",
    "\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            lines = [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n",
    "\n",
    "#         lines = lines[:50_000]\n",
    "        batch_encoding = tokenizer.batch_encode_plus(lines, add_special_tokens=True, max_length=tokenizer.vocab_size)\n",
    "        self.examples = batch_encoding[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i) -> torch.Tensor:\n",
    "        return torch.tensor(self.examples[i], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.tensor(tokenizer.encode(\"ALKLAKALK\", \n",
    "#                                           add_special_tokens=True, \n",
    "#                                           max_length=SEQ_LEN, \n",
    "#                                           pad_to_max_length=True)).unsqueeze(0)  # Batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
